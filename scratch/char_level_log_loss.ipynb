{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d8de803",
   "metadata": {},
   "source": [
    "See https://huggingface.co/google/reformer-enwik8#reformer-language-model-on-character-level-and-trained-on-enwik8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d81bd8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Encoding\n",
    "def encode(list_of_strings, pad_token_id=0):\n",
    "    max_length = max([len(string) for string in list_of_strings])\n",
    "\n",
    "    # create emtpy tensors\n",
    "    attention_masks = torch.zeros((len(list_of_strings), max_length), dtype=torch.long)\n",
    "    input_ids = torch.full((len(list_of_strings), max_length), pad_token_id, dtype=torch.long)\n",
    "\n",
    "    for idx, string in enumerate(list_of_strings):\n",
    "        # make sure string is in byte format\n",
    "        if not isinstance(string, bytes):\n",
    "            string = str.encode(string)\n",
    "\n",
    "        input_ids[idx, :len(string)] = torch.tensor([x + 2 for x in string])\n",
    "        attention_masks[idx, :len(string)] = 1\n",
    "\n",
    "    return input_ids, attention_masks\n",
    "    \n",
    "# Decoding\n",
    "def decode(outputs_ids):\n",
    "    decoded_outputs = []\n",
    "    for output_ids in outputs_ids.tolist():\n",
    "        # transform id back to char IDs < 2 are simply transformed to \"\"\n",
    "        decoded_outputs.append(\"\".join([chr(x - 2) if x > 1 else \"\" for x in output_ids]))\n",
    "    return decoded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2259cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ReformerModelWithLMHead\n",
    "\n",
    "model = ReformerModelWithLMHead.from_pretrained(\"google/reformer-enwik8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12c6c58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In the year 1961, re']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded, attention_masks = encode([\"In the year 1961\"])\n",
    "decode(model.generate(encoded, do_sample=True, max_length=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d5ccd1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100,   51]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = encoded\n",
    "masked = input_ids.clone()\n",
    "masked[:, :-1] = -100\n",
    "masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9eb2bfc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "483ae4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.forward(input_ids=input_ids, labels=masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0f879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            # Flatten the tokens\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(shift_logits.view(-1, self.config.vocab_size), shift_labels.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cac9544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "00bc4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1363, grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.loss.neg().exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90fa71aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"1602345879 .],<\\nt&)'\"]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_token_logits = out.logits[0, -2, :]\n",
    "decode(last_token_logits.topk(20).indices.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "998beeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0522e-03, 3.4218e-03, 7.4647e-02, 4.2927e-04, 1.0230e-05, 1.6872e-05,\n",
       "         2.0796e-02, 6.7687e-06, 1.1147e-07, 3.2344e-06, 3.3391e-05, 4.1315e-01,\n",
       "         9.1986e-02, 1.0991e-01, 1.3634e-01, 7.9240e-07]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.logits.softmax(dim=2)[:, :, 51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d2946ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3634e-01, 1.3585e-01, 1.2241e-01, 1.0184e-01, 1.0049e-01, 1.0026e-01,\n",
       "        8.9645e-02, 8.1478e-02, 7.2285e-02, 5.6066e-02, 1.1347e-03, 3.4175e-04,\n",
       "        2.1189e-04, 1.5333e-04, 1.0002e-04, 9.7569e-05, 9.2751e-05, 9.1451e-05,\n",
       "        7.6007e-05, 5.8729e-05], grad_fn=<TopkBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_token_logits.softmax(dim=0).topk(20).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b97fcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.992603513047498"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.log(1.3634e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8700332c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7334604664808567"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/1.3634"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
