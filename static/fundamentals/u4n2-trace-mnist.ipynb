{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96848edf",
   "metadata": {},
   "source": [
    "# Trace Simple Image Classifier\n",
    "\n",
    "Task: trace and explain the dimensionality of each tensor in a simple image classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e7193",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf51f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5717f1e8",
   "metadata": {},
   "source": [
    "Get some example digits from the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9095b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6cd3f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "len(threes), len(sevens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8180c642",
   "metadata": {},
   "source": [
    "Here is one image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54fa7557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9ElEQVR4nM3Or0sDcRjH8c/pgrfBVBjCgibThiKIyTWbWF1bORhGwxARxH/AbtW0JoIGwzXRYhJhtuFY2q1ocLgbe3sGReTuuWbwkx6+r+/zQ/pncX6q+YOldSe6nG3dn8U/rTQ70L8FCGJUewvxl7NTmezNb8xIkvKugr1HSeMP6SrWOVkoTEuSyh0Gm2n3hQyObMnXnxkempRrvgD+gokzwxFAr7U7YXHZ8x4A/Dl7rbu6D2yl3etcw/F3nZgfRVI7rXM7hMUUqzzBec427x26rkmlkzEEa4nnRqnSOH2F0UUx0ePzlbuqMXAHgN6GY9if5xP8dmtHFfwjuQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x109670C70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_3 = Image.open(threes[1])\n",
    "example_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d16aed",
   "metadata": {},
   "source": [
    "To prepare to use it as input to a neural net, we first convert integers from 0 to 255 into floating point numbers between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7406d76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_3_tensor = tensor(example_3).float() / 255\n",
    "example_3_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de44e0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = example_3_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647e66e8",
   "metadata": {},
   "source": [
    "Our particular network will ignore the spatial relationship between the features; later we'll learn about network architectures that do pay attention to spatial neighbors. So we'll *flatten* the image tensor into 28\\*28 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c43e173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_3_flat = example_3_tensor.view(width * height)\n",
    "example_3_flat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edee9e07",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fcae10",
   "metadata": {},
   "source": [
    "We'll define a simple neural network (in the book, a 3-vs-7 classifier) as the sequential combination of 3 layers. First we define each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca205bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the layers. This is where you'll try changing constants.\n",
    "linear_1 = nn.Linear(in_features=784, out_features=30)\n",
    "relu_layer = nn.ReLU()\n",
    "linear_2 = nn.Linear(in_features=30, out_features=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90861399",
   "metadata": {},
   "source": [
    "Then we put them together in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4502d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    linear_1,\n",
    "    relu_layer,\n",
    "    linear_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9b2970",
   "metadata": {},
   "source": [
    "Each of `nn.Linear`, `nn.ReLU`, and `nn.Squential` are PyTorch *modules*. We can *call* a module with some input data to get the output data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b55251f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1385], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_net(example_3_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1189506e",
   "metadata": {},
   "source": [
    "Your turn:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f479d8e7",
   "metadata": {},
   "source": [
    "1. Obtain the same result as the line above by applying each layer in sequence.\n",
    "\n",
    "The outputs of each layer are called *activations*, so we can name the variables `act1` for the activations of layer 1, and so forth. Each `act` will be a function of the previous `act` (or the `inp`ut, for the first layer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ffb847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = example_3_flat\n",
    "act1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8f52ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "act2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06cc6aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "act3 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555cf6ec",
   "metadata": {},
   "source": [
    "2. Evaluate `act1`, `act2`, and `act3`. (Code already provided; look at the results.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71fb50cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1971, -0.2886,  0.2023, -0.0984,  0.1338, -0.1604,  0.2701, -0.3103,  0.2313,  0.1280, -0.3245,  0.1302, -0.1761, -0.1394,  0.0234, -0.1384,  0.3531,  0.5236, -0.1388,  0.1109,  0.0033,\n",
       "         0.1793, -0.3673, -0.0706, -0.1324, -0.4853,  0.3566,  0.1476, -0.2868, -0.0929], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "717a140f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.2023, 0.0000, 0.1338, 0.0000, 0.2701, 0.0000, 0.2313, 0.1280, 0.0000, 0.1302, 0.0000, 0.0000, 0.0234, 0.0000, 0.3531, 0.5236, 0.0000, 0.1109, 0.0033, 0.1793, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.3566, 0.1476, 0.0000, 0.0000], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "021ede80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1385], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff68adbd",
   "metadata": {},
   "source": [
    "2. Evaluate the `shape` of `act1`, `act2`, and `act3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e8cf98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([30]), torch.Size([30]), torch.Size([1]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9271b1",
   "metadata": {},
   "source": [
    "3. Write expressions for the shapes of each activation in terms of `linear_1.in_features`, `linear_2.out_features`, etc. (ignore the `torch.Size(` part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d9f61bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_1.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffd3a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "act1_shape = [...]\n",
    "act2_shape = [...]\n",
    "act3_shape = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed4000",
   "metadata": {},
   "source": [
    "4. Evaluate the `shape` of `linear_1.weight`, `linear_1.bias`, and the same for `linear_2`. Write expressions that give the value of each shape in terms of the `in_features` and other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2693adf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear 1: Weight shape is [30, 784], bias shape is [30]\n",
      "Linear 2: Weight shape is [1, 30], bias shape is [1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Linear 1: Weight shape is {list(linear_1.weight.shape)}, bias shape is {list(linear_1.bias.shape)}\")\n",
    "print(f\"Linear 2: Weight shape is {list(linear_2.weight.shape)}, bias shape is {list(linear_2.bias.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85b69231",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_1_weight_shape = [...]\n",
    "linear_1_bias_shape = [...]\n",
    "linear_2_weight_shape = [...]\n",
    "linear_2_bias_shape = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58eba766",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert list(linear_1_weight_shape) == list(linear_1.weight.shape)\n",
    "assert list(linear_1_bias_shape) == list(linear_1.bias.shape)\n",
    "assert list(linear_2_weight_shape) == list(linear_2.weight.shape)\n",
    "assert list(linear_2_bias_shape) == list(linear_2.bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c76d8e1",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb578c72",
   "metadata": {},
   "source": [
    "1. Try changing each of the constants provided to the `nn.Linear` modules. Identify an example of:\n",
    "    1. A constant that can be freely changed in the neural net definition.\n",
    "    2. A constant that cannot be changed because it depends on the input.\n",
    "    3. A pair of constants that must be changed together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292a8c7c",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d971",
   "metadata": {},
   "source": [
    "2. Describe the relationship between the values in  `act1` and `act2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f5d8f1",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3497b0bc",
   "metadata": {},
   "source": [
    "3. In a concise but complete sentence, describe the shapes of the parameters of the `Linear` layer (`weight` and `bias`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb2053",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
